{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **VGG-Implementation**\n",
    "\n",
    "Small introduction about the implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Importing required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import random\n",
    "import urllib.request\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score,recall_score\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, random_split\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = {\n",
    "    \"train_images\": \"https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\",\n",
    "    \"train_labels\": \"https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\",\n",
    "    \"test_images\": \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\",\n",
    "    \"test_labels\": \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Official URL dataset extract fails - http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download and extract files\n",
    "def download_and_extract(url, path, is_label=False):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Downloading {url}...\")\n",
    "        urllib.request.urlretrieve(url, path)\n",
    "        print(f\"Downloaded {path}\")\n",
    "    else:\n",
    "        print(f\"{path} already exists, skipping download.\")\n",
    "\n",
    "    offset = 8 if is_label else 16 # Handle labels separately as their header is 8 bytes instead of 16\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        return np.frombuffer(f.read(), np.uint8, offset=offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/train-images.gz already exists, skipping download.\n",
      "./data/train-labels.gz already exists, skipping download.\n",
      "./data/test-images.gz already exists, skipping download.\n",
      "./data/test-labels.gz already exists, skipping download.\n",
      "MNIST data downloaded and loaded.\n"
     ]
    }
   ],
   "source": [
    "def load_mnist_data():\n",
    "    os.makedirs('./data', exist_ok=True)\n",
    "\n",
    "    train_images = download_and_extract(urls['train_images'], './data/train-images.gz')\n",
    "    train_labels = download_and_extract(urls['train_labels'], './data/train-labels.gz', is_label=True)\n",
    "    test_images = download_and_extract(urls['test_images'], './data/test-images.gz')\n",
    "    test_labels = download_and_extract(urls['test_labels'], './data/test-labels.gz', is_label=True)\n",
    "\n",
    "    # Reshape and normalize the images\n",
    "    train_images = train_images.reshape(-1, 28, 28) / 255.0\n",
    "    test_images = test_images.reshape(-1, 28, 28) / 255.0\n",
    "\n",
    "    # Combine train and test datasets for custom split\n",
    "    images = np.concatenate((train_images, test_images), axis=0)\n",
    "    labels = np.concatenate((train_labels, test_labels), axis=0)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "images, labels = load_mnist_data()\n",
    "print(\"MNIST data downloaded and loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2 Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 42000\n",
      "Validation set size: 14000\n",
      "Test set size: 14000\n"
     ]
    }
   ],
   "source": [
    "def split_data(images, labels):\n",
    "    total_size = len(images)\n",
    "\n",
    "    # Sizes for each split\n",
    "    train_size = int(0.6 * total_size)\n",
    "    val_size = int(0.2 * total_size)\n",
    "    test_size = total_size - train_size - val_size\n",
    "\n",
    "    train_images, train_labels = images[:train_size], labels[:train_size]\n",
    "    val_images, val_labels = images[train_size:train_size+val_size], labels[train_size:train_size+val_size]\n",
    "    test_images, test_labels = images[train_size+val_size:], labels[train_size+val_size:]\n",
    "\n",
    "    return (train_images, train_labels), (val_images, val_labels), (test_images, test_labels)\n",
    "\n",
    "# Split into training, validation, and testing sets (60%, 20%, 20%)\n",
    "(train_images, train_labels), (val_images, val_labels), (test_images, test_labels) = split_data(images, labels)\n",
    "\n",
    "print(f\"Training set size: {len(train_images)}\")\n",
    "print(f\"Validation set size: {len(val_images)}\")\n",
    "print(f\"Test set size: {len(test_images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Numpy arrays into tensor format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        # Convert numpy arrays to torch tensors\n",
    "        self.images = torch.tensor(images, dtype=torch.float32).unsqueeze(1)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long).clone().detach()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]\n",
    "\n",
    "    def get_images(self):\n",
    "        return self.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch image shape: torch.Size([64, 1, 28, 28]), Batch label shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Create dataset objects\n",
    "train_dataset = MNISTDataset(train_images, train_labels)\n",
    "val_dataset = MNISTDataset(val_images, val_labels)\n",
    "test_dataset = MNISTDataset(test_images, test_labels)\n",
    "\n",
    "# Create DataLoader objects\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "train_iter = iter(train_loader)\n",
    "images, labels = next(train_iter)\n",
    "print(f\"Batch image shape: {images.shape}, Batch label shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in train_dataset: 42000\n",
      "Number of rows in test_dataset: 14000\n",
      "Number of rows in val_dataset: 14000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows in train_dataset: {len(train_dataset)}\")\n",
    "print(f\"Number of rows in test_dataset: {len(test_dataset)}\")\n",
    "print(f\"Number of rows in val_dataset: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Model Building**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Model Creation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Preprocessing for grayscale images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert 1-channel to 3-channel\n",
    "    transforms.Resize((224, 224)),                # Resize to VGG16 input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "# Update dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E: 0] loss: 2.322901, avg_loss: 2.322901\n",
      "[E: 0] loss: 77.279266, avg_loss: 39.801083\n",
      "[E: 0] loss: 138.544617, avg_loss: 72.715595\n",
      "[E: 0] loss: 114.744499, avg_loss: 83.222821\n",
      "[E: 0] loss: 74.535858, avg_loss: 81.485428\n",
      "[E: 0] loss: 65.646431, avg_loss: 78.845595\n",
      "[E: 0] loss: 63.372414, avg_loss: 76.635141\n",
      "[E: 0] loss: 50.825844, avg_loss: 73.408979\n",
      "[E: 0] loss: 39.005375, avg_loss: 69.586356\n",
      "[E: 0] loss: 26.294472, avg_loss: 65.257168\n",
      "[E: 0] loss: 21.978323, avg_loss: 61.322727\n",
      "[E: 0] loss: 12.326973, avg_loss: 57.239748\n",
      "[E: 0] loss: 6.511987, avg_loss: 53.337612\n",
      "[E: 0] loss: 19.193344, avg_loss: 50.898736\n",
      "[E: 0] loss: 4.866952, avg_loss: 47.829950\n",
      "[E: 0] loss: 7.894782, avg_loss: 45.334002\n",
      "[E: 0] loss: 4.171123, avg_loss: 42.912656\n",
      "[E: 0] loss: 4.377792, avg_loss: 40.771831\n",
      "[E: 0] loss: 2.648678, avg_loss: 38.765349\n",
      "[E: 0] loss: 3.017067, avg_loss: 36.977935\n",
      "[E: 0] loss: 2.350429, avg_loss: 35.329006\n",
      "[E: 0] loss: 3.500649, avg_loss: 33.882262\n",
      "[E: 0] loss: 2.214882, avg_loss: 32.505420\n",
      "[E: 0] loss: 2.505168, avg_loss: 31.255409\n",
      "[E: 0] loss: 2.111124, avg_loss: 30.089638\n",
      "[E: 0] loss: 1.922411, avg_loss: 29.006283\n",
      "[E: 0] loss: 1.924345, avg_loss: 28.003248\n",
      "[E: 0] loss: 1.902280, avg_loss: 27.071071\n",
      "[E: 0] loss: 1.855885, avg_loss: 26.201582\n",
      "[E: 0] loss: 1.891505, avg_loss: 25.391246\n",
      "[E: 0] loss: 1.621464, avg_loss: 24.624479\n",
      "[E: 0] loss: 1.530535, avg_loss: 23.902793\n",
      "[E: 0] loss: 1.556217, avg_loss: 23.225624\n",
      "[E: 0] loss: 1.565311, avg_loss: 22.588556\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define constants\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE = 0.1\n",
    "N_CLASSES = 10\n",
    "EPOCH = 10\n",
    "\n",
    "def conv_layer(channel_in, channel_out, k_size, p_size):\n",
    "    layer = nn.Sequential(\n",
    "        nn.Conv2d(channel_in, channel_out, kernel_size=k_size, padding=p_size),\n",
    "        nn.BatchNorm2d(channel_out),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "    return layer\n",
    "\n",
    "def vgg_conv_block(in_List, out_list, k_list, p_list, pooling_k, pooling_s):\n",
    "    layers = [conv_layer(in_List[i], out_list[i], k_list[i], p_list[i]) for i in range(len(in_List))]\n",
    "    layers += [nn.MaxPool2d(kernel_size=pooling_k, stride=pooling_s)]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def vgg_fc_layer(size_in, size_out):\n",
    "    layer = nn.Sequential(\n",
    "        nn.Linear(size_in, size_out),\n",
    "        nn.BatchNorm1d(size_out),  # Changed from BatchNorm2d to BatchNorm1d\n",
    "        nn.ReLU()\n",
    "    )\n",
    "    return layer\n",
    "\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self, n_classes=1000):\n",
    "        super(VGG16, self).__init__()\n",
    "\n",
    "        # Conv blocks (BatchNorm + ReLU activation added in each block)\n",
    "        self.layer1 = vgg_conv_block([3, 64], [64, 64], [3, 3], [1, 1], 2, 2)\n",
    "        self.layer2 = vgg_conv_block([64, 128], [128, 128], [3, 3], [1, 1], 2, 2)\n",
    "        self.layer3 = vgg_conv_block([128, 256, 256], [256, 256, 256], [3, 3, 3], [1, 1, 1], 2, 2)\n",
    "        self.layer4 = vgg_conv_block([256, 512, 512], [512, 512, 512], [3, 3, 3], [1, 1, 1], 2, 2)\n",
    "        self.layer5 = vgg_conv_block([512, 512, 512], [512, 512, 512], [3, 3, 3], [1, 1, 1], 2, 2)\n",
    "\n",
    "        # FC layers\n",
    "        self.layer6 = vgg_fc_layer(7 * 7 * 512, 4096)\n",
    "        self.layer7 = vgg_fc_layer(4096, 4096)\n",
    "\n",
    "        # Final layer\n",
    "        self.layer8 = nn.Linear(4096, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        vgg16_features = self.layer5(out)\n",
    "        out = vgg16_features.view(out.size(0), -1)\n",
    "        out = self.layer6(out)\n",
    "        out = self.layer7(out)\n",
    "        out = self.layer8(out)\n",
    "\n",
    "        return vgg16_features, out\n",
    "\n",
    "# Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "vgg16 = VGG16(n_classes=N_CLASSES).to(device)\n",
    "\n",
    "# Loss, Optimizer & Scheduler\n",
    "cost = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(vgg16.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "# Training\n",
    "for epoch in range(EPOCH):\n",
    "    avg_loss = 0.0\n",
    "    cnt = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        _, outputs = vgg16(images)\n",
    "        loss = cost(outputs, labels)\n",
    "        avg_loss += loss.item()\n",
    "        cnt += 1\n",
    "        print(\"[E: %d] loss: %f, avg_loss: %f\" % (epoch, loss.item(), avg_loss / cnt))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step(avg_loss / cnt)\n",
    "\n",
    "# Testing\n",
    "vgg16.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    _, outputs = vgg16(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    print(predicted, labels, correct, total)\n",
    "print(\"Average Accuracy: %f\" % (100 * correct / total))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProjectCNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
